# Mekari Associate AI Engineer Challenge Test: Q&A Chatbot

This projects implements a Q&A Chatbot, which focuses on building a robust internal system capable of answering fraud-related questions using two fundamentally different sources of information: [a tabular credit-card transaction dataset](https://www.kaggle.com/datasets/kartik2112/fraud-detection/data?select=fraud%20dataset) and [a document explaining real-world fraud mechanisms](https://popcenter.asu.edu/sites/g/files/litvpz3631/files/problems/credit_card_fraud/PDFs/Bhatla.pdf). The primary challenge is to design an intelligent agent that can understand a userâ€™s question, determine the appropriate knowledge source, extract and synthesize correct information, and deliver clear, accurate insights.

At its core, this project is engineered as a modular pipeline that separates concerns cleanly: data processing, PostgreSQL relational database for transaction dataset, Qdrant vector database for document embedding, FastAPI backend for LLM orchestration, and Streamlit frontend for interaction.

[Click here to learn more about the project: mekari-qac/assets/Mekari - AI Engineer.pdf](https://github.com/verneylmavt/mekari-qac/blob/ec7788fa0749925197eb3379c2ed9b6e56e4d5f2/assets/Mekari%20-%20AI%20Engineer.pdf).

## ğŸ“ Project Structure

```
mekari-qac
â”‚
â”œâ”€â”€ data/                                     # Dataset and data processing
â”‚   â”œâ”€â”€ fraudData/
â”‚   â”‚   â”œâ”€â”€ fraudTrain.csv                    # Training split of credit card transaction dataset
â”‚   â”‚   â”œâ”€â”€ fraudTest.csv                     # Test split of credit card transaction dataset
â”‚   â”‚   â”œâ”€â”€ data_processing_fraudData.ipynb   # Data processing notebook for credit card transaction dataset
â”‚   â”‚   â”œâ”€â”€ fraudData_snapshot.dump           # DB snapshot
â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â”‚
â”‚   â””â”€â”€ Understanding Credit Card Frauds/
â”‚       â”œâ”€â”€ Bhatla.pdf                                              # Credit card fraud document
â”‚       â”œâ”€â”€ data_processing_Understanding Credit Card Frauds.ipynb  # Data processing notebook for credit card fraud document
â”‚       â”œâ”€â”€ Bhatla_chunks.json                                      # Cleaned and segmented text chunks
â”‚       â”œâ”€â”€ Bhatla_embeddings.npy                                   # Precomputed dense embeddings
â”‚       â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ backend/                                  # FastAPI backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py                           # REST API: /health, /chat
â”‚   â”‚   â”œâ”€â”€ config.py                         # Environment variables + global configuration
â”‚   â”‚   â”œâ”€â”€ db.py                             # PostgreSQL engine creation + connection handling
â”‚   â”‚   â”œâ”€â”€ schemas.py                        # Pydantic request/response models
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ agent/
â”‚   â”‚   â”‚   â”œâ”€â”€ state.py                      # Central AgentState + shared memory fields
â”‚   â”‚   â”‚   â”œâ”€â”€ graph.py                      # Routing graph: data, document, fallback, scoring
â”‚   â”‚   â”‚   â”œâ”€â”€ router.py                     # LLM question router: data vs document vs none
â”‚   â”‚   â”‚   â”œâ”€â”€ data_nodes.py                 # SQL generator, SQL executor, and data explanation nodes
â”‚   â”‚   â”‚   â”œâ”€â”€ doc_nodes.py                  # Qdrant retrieval + RAG answer generator
â”‚   â”‚   â”‚   â””â”€â”€ scoring_node.py               # Quality-scoring node for evaluating LLM answers
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”‚   â””â”€â”€ client.py                     # GPT-5-Nano/Mini wrappers for chat/completions
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ rag/
â”‚   â”‚   â”‚   â””â”€â”€ qdrant_client.py              # Embedding, retrieval, reranking + Qdrant connection
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ repositories/
â”‚   â”‚       â””â”€â”€ metrics_repo.py               # SQL execution helper for querying analytics tables/views
â”‚   â”‚
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ frontend/                                 # Streamlit frontend
â”‚   â”œâ”€â”€ app.py                                # Streamlit interface: health check, chat UI
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ scripts/                                  # Initialization scripts
â”‚   â”œâ”€â”€ init_postgresql.py                    # Script to initialize PostgreSQL
â”‚   â””â”€â”€ init_qdrant.py                        # Script to initialize Qdrant
â”‚
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ q&a_chatbot_fastapi_demo.mp4          # Demo video for FastAPI Server
â”‚   â””â”€â”€ q&a_chatbot_streamlit_demo.mp4        # Demo video for Streamlit UI
â”‚
â”œâ”€â”€ .env
â””â”€â”€ requirements.txt
```

## ğŸ§© Components

## ğŸ”Œ API

1. **Health Check**
   `GET /health`: to verify that the FastAPI server, PostgreSQL, Qdrant is running
   - Request: `None`
   - Response: `'status', 'db_ok', 'qdrant_ok', 'model'`
   ```bash
   curl "http://localhost:8000/health"
   ```
2. **Chat w/ Fraud Q&A Chatbot**
   `POST /chat`: to ask the chatbot about credit card transaction or credit card fraud
   - Request: `ChatRequest`
   - Response: `ChatResponse`
   ```bash
   curl -X PUT "http://localhost:8000/chat" \
   -H "Content-Type: application/json" \
   -d '{
      "question": "{question}",
      "history": [
            {"role": "user", "content": "{user_content}"},
            {"role": "assistant", "content": "{assistant_content}"}
        ]
   }'
   ```

## ğŸ–¥ï¸ Demo Video

- **FastAPI Server**
  ![FastAPI Server](https://media.githubusercontent.com/media/verneylmavt/mekari-qac/refs/heads/main/assets/q%26a_chatbot_fastapi_demo.gif)

- **Streamlit UI**
  ![Streamlit UI](https://media.githubusercontent.com/media/verneylmavt/mekari-qac/refs/heads/main/assets/q%26a_chatbot_streamlit_demo.gif)

## âš™ï¸ Local Setup

0. Make sure to have the prerequisites:

   - Git
   - Git Large File Storage
   - Python
   - Conda or venv
   - Docker
   - NVIDIA Driver + CUDA Toolkit (optional)

1. Clone the repository:

   ```bash
    git clone https://github.com/verneylmavt/mekari-qac.git
    cd mekari-qac
   ```

2. Create environment and install dependencies:

   ```bash
   conda create -n mekari-qac python=3.11 -y
   conda activate mekari-qac

   pip install -r requirements.txt
   ```

3. Fill the required `OPENAI_API_KEY` in `.env`

4. Initialize and run the required components:

   - Initialize the PostgreSQL:
     ```bash
     python scripts/init_postgresql.py
     ```
   - Initialize the Qdrant:
     ```bash
     python scripts/init_qdrant.py
     ```
   - Run the FastAPI backend server:
     ```bash
     uvicorn backend.app.main:app --reload --port 8000
     ```
   - Run the Streamlit frontend UI:
     ```bash
     streamlit run frontend/app.py
     ```

5. Open the API documentation to make an API call:
   ```bash
   start "http://127.0.0.1:8000/docs"
   ```
   Or alternatively, open the UI and interact with the app:
   ```bash
   start "http://127.0.0.1:8501"
   ```
