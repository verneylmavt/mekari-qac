{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8e9a0cf",
   "metadata": {},
   "source": [
    "## Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91452ad",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "044d5ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import uuid\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from docx import Document\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import QueryResponse\n",
    "from qdrant_client.http import models as qmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8473b2c",
   "metadata": {},
   "source": [
    "### Config & Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c08f86c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "docx_path = \"Bhatla_Description.docx\"\n",
    "\n",
    "qdrant_url = \"http://localhost:6333\"\n",
    "qdrant_collection = \"bhatla_credit_fraud\"\n",
    "\n",
    "embed_model_name = \"BAAI/bge-base-en-v1.5\"\n",
    "embed_dim = 768\n",
    "\n",
    "reranker_model_name = \"BAAI/bge-reranker-base\"\n",
    "\n",
    "max_tokens_per_chunk = 256\n",
    "chunk_overlap_sentences = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e291dbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9e42c7",
   "metadata": {},
   "source": [
    "### Dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "308d308b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Paragraph or Heading\n",
    "@dataclass\n",
    "class RawElement:\n",
    "    type: str\n",
    "    level: Optional[int]\n",
    "    text: str\n",
    "\n",
    "# for Section\n",
    "@dataclass\n",
    "class Block:\n",
    "    section: Optional[str]\n",
    "    subsection: Optional[str]\n",
    "    text: str\n",
    "    block_index: int\n",
    "\n",
    "# for Text\n",
    "@dataclass\n",
    "class Chunk:\n",
    "    chunk_id: str\n",
    "    section: Optional[str]\n",
    "    subsection: Optional[str]\n",
    "    block_index: int\n",
    "    chunk_index: int\n",
    "    text: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6d4fb4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bullet_chars = [\"•\", \"·\", \"●\", \"■\", \"▪\", \"¤\", \"-\", \"–\", \"—\"]\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    text = text.replace(\"\\xa0\", \" \")\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "def is_all_caps(text: str) -> bool:\n",
    "    stripped = re.sub(r\"[^A-Za-z]\", \"\", text)\n",
    "    return stripped.isupper() and len(stripped) > 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e486f943",
   "metadata": {},
   "source": [
    "### Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8dbe0f",
   "metadata": {},
   "source": [
    "#### Data Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3f8f7557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_docx_to_raw_elements(docx_path: str) -> List[RawElement]:\n",
    "    doc = Document(docx_path)\n",
    "    elements: List[RawElement] = []\n",
    "\n",
    "    for para in doc.paragraphs:\n",
    "        text = clean_text(para.text)\n",
    "        if not text:\n",
    "            continue\n",
    "\n",
    "        style_name = para.style.name if para.style else \"\"\n",
    "\n",
    "        level = None\n",
    "        elem_type = \"paragraph\"\n",
    "\n",
    "        if style_name.startswith(\"Heading\"):\n",
    "            elem_type = \"heading\"\n",
    "            try:\n",
    "                level = int(style_name.split()[-1])\n",
    "            except ValueError:\n",
    "                level = 1\n",
    "        else:\n",
    "            if is_all_caps(text) and len(text.split()) <= 6:\n",
    "                elem_type = \"heading\"\n",
    "                level = 2\n",
    "\n",
    "        elements.append(RawElement(type=elem_type, level=level, text=text))\n",
    "\n",
    "    return elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f3f69f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Raw Elements: 186\n",
      "First 5 Raw Elements:\n",
      "  type=paragraph, level=None, text='Cards Business Review#2003–01...'\n",
      "  type=paragraph, level=None, text='Understanding Credit Card Frauds...'\n",
      "  type=paragraph, level=None, text='Tej Paul Bhatla, Vikram Prabhu & Amit Dua...'\n",
      "  type=paragraph, level=None, text='June 2003...'\n",
      "  type=paragraph, level=None, text='© Tata Consultancy Services 2002. All rights reserved....'\n"
     ]
    }
   ],
   "source": [
    "raw_elements = parse_docx_to_raw_elements(docx_path)\n",
    "print(f\"Number of Raw Elements: {len(raw_elements)}\")\n",
    "print(\"First 5 Raw Elements:\")\n",
    "for el in raw_elements[:5]:\n",
    "    print(f\"  type={el.type}, level={el.level}, text='{el.text[:80]}...'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5a488756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_blocks_from_elements(elements: List[RawElement]) -> List[Block]:\n",
    "    blocks: List[Block] = []\n",
    "    current_section: Optional[str] = None\n",
    "    current_subsection: Optional[str] = None\n",
    "    current_paragraphs: List[str] = []\n",
    "    block_index = 0\n",
    "\n",
    "    def flush_block():\n",
    "        nonlocal block_index, current_paragraphs\n",
    "        if current_paragraphs:\n",
    "            text = \" \".join(current_paragraphs).strip()\n",
    "            blocks.append(\n",
    "                Block(\n",
    "                    section=current_section,\n",
    "                    subsection=current_subsection,\n",
    "                    text=text,\n",
    "                    block_index=block_index,\n",
    "                )\n",
    "            )\n",
    "            block_index += 1\n",
    "            current_paragraphs = []\n",
    "\n",
    "    for el in elements:\n",
    "        if el.type == \"heading\":\n",
    "            flush_block()\n",
    "            if el.level is None or el.level == 1:\n",
    "                current_section = el.text\n",
    "                current_subsection = None\n",
    "            elif el.level == 2:\n",
    "                current_subsection = el.text\n",
    "            else:\n",
    "                current_paragraphs.append(el.text)\n",
    "        else:\n",
    "            current_paragraphs.append(el.text)\n",
    "\n",
    "    flush_block()\n",
    "\n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "cf1bb232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Blocks: 31\n",
      "First 5 Blocks:\n",
      "  block_index=0, section=None, subsection=None\n",
      "    text='Cards Business Review#2003–01 Understanding Credit Card Frauds Tej Paul Bhatla, Vikram Prabhu & Amit Dua June 2003 © Tat...'\n",
      "  block_index=1, section=Introduction, subsection=None\n",
      "    text='Credit Card Fraud is one of the biggest threats to business establishments today. However, to combat the fraud effective...'\n",
      "  block_index=2, section=Purpose of this Paper, subsection=None\n",
      "    text='The purpose of this white paper is to study: State of the credit card industry, Different types of frauds, How fraudster...'\n",
      "  block_index=3, section=Current State of the Industry, subsection=None\n",
      "    text='While the exact amount of losses due to fraudulent activities on cards is unknown, various research analyst reports conc...'\n",
      "  block_index=4, section=How Fraud is Committed Worldwide?, subsection=None\n",
      "    text='While lost or stolen card is the most common type of fraud, others include identity theft, skimming, counterfeit card, m...'\n"
     ]
    }
   ],
   "source": [
    "blocks = build_blocks_from_elements(raw_elements)\n",
    "print(f\"Number of Blocks: {len(blocks)}\")\n",
    "print(\"First 5 Blocks:\")\n",
    "for b in blocks[:5]:\n",
    "    print(f\"  block_index={b.block_index}, section={b.section}, subsection={b.subsection}\")\n",
    "    print(f\"    text='{b.text[:120]}...'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "cc9f5f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blocks\n",
      "  Number of Blocks: 31\n",
      "  Number of Characters: 39544\n",
      "  Number of Words: 6121\n",
      "  Chars per Block: 1275.61\n",
      "  Words per Block: 197.45\n"
     ]
    }
   ],
   "source": [
    "total_block_chars = sum(len(b.text) for b in blocks)\n",
    "total_block_words = sum(len(b.text.split()) for b in blocks)\n",
    "\n",
    "print(\"Blocks\")\n",
    "print(f\"  Number of Blocks: {len(blocks)}\")\n",
    "print(f\"  Number of Characters: {total_block_chars}\")\n",
    "print(f\"  Number of Words: {total_block_words}\")\n",
    "print(f\"  Chars per Block: {total_block_chars / len(blocks):.2f}\")\n",
    "print(f\"  Words per Block: {total_block_words / len(blocks):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedfbda1",
   "metadata": {},
   "source": [
    "#### Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6da19e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_sentences(text: str) -> List[str]:\n",
    "    sentences = sent_tokenize(text)\n",
    "    return [s.strip() for s in sentences if s.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c13035f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_block(\n",
    "    blk: Block,\n",
    "    max_tokens: int = max_tokens_per_chunk,\n",
    "    overlap_sentences: int = chunk_overlap_sentences,\n",
    ") -> List[Chunk]:\n",
    "    sentences = split_into_sentences(blk.text)\n",
    "    chunks_list: List[Chunk] = []\n",
    "    current_sentences: List[str] = []\n",
    "    current_count = 0\n",
    "    chunk_index = 0\n",
    "\n",
    "    i = 0\n",
    "    while i < len(sentences):\n",
    "        s = sentences[i]\n",
    "        num_tokens = len(s.split())\n",
    "\n",
    "        if current_sentences and current_count + num_tokens > max_tokens:\n",
    "            chunk_text = \" \".join(current_sentences).strip()\n",
    "            chunk_id = str(uuid.uuid4())\n",
    "            chunks_list.append(\n",
    "                Chunk(\n",
    "                    chunk_id=chunk_id,\n",
    "                    section=blk.section,\n",
    "                    subsection=blk.subsection,\n",
    "                    block_index=blk.block_index,\n",
    "                    chunk_index=chunk_index,\n",
    "                    text=chunk_text,\n",
    "                )\n",
    "            )\n",
    "            chunk_index += 1\n",
    "\n",
    "            overlap = current_sentences[-overlap_sentences:] if overlap_sentences > 0 else []\n",
    "            current_sentences = overlap.copy()\n",
    "            current_count = sum(len(sen.split()) for sen in current_sentences)\n",
    "\n",
    "        current_sentences.append(s)\n",
    "        current_count += num_tokens\n",
    "        i += 1\n",
    "\n",
    "    if current_sentences:\n",
    "        chunk_text = \" \".join(current_sentences).strip()\n",
    "        chunk_id = str(uuid.uuid4())\n",
    "        chunks_list.append(\n",
    "            Chunk(\n",
    "                chunk_id=chunk_id,\n",
    "                section=blk.section,\n",
    "                subsection=blk.subsection,\n",
    "                block_index=blk.block_index,\n",
    "                chunk_index=chunk_index,\n",
    "                text=chunk_text,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return chunks_list\n",
    "\n",
    "\n",
    "def build_all_chunks(blocks: List[Block]) -> List[Chunk]:\n",
    "    all_chunks: List[Chunk] = []\n",
    "    for blk in blocks:\n",
    "        block_chunks = chunk_block(blk)\n",
    "        all_chunks.extend(block_chunks)\n",
    "    return all_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "690c9da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Chunks: 43\n",
      "Sample Chunk:\n",
      "  id=b3d3c25b-d32e-4a81-9307-232b2ab4450d\n",
      "  section=None, subsection=None\n",
      "  text length (chars)=169\n",
      "  text snippet='Cards Business Review#2003–01 Understanding Credit Card Frauds Tej Paul Bhatla, Vikram Prabhu & Amit Dua June 2003 © Tata Consultancy Services 2002. All rights reserved....'\n"
     ]
    }
   ],
   "source": [
    "chunks = build_all_chunks(blocks)\n",
    "print(f\"Number of Chunks: {len(chunks)}\")\n",
    "print(\"Sample Chunk:\")\n",
    "print(f\"  id={chunks[0].chunk_id}\")\n",
    "print(f\"  section={chunks[0].section}, subsection={chunks[0].subsection}\")\n",
    "print(f\"  text length (chars)={len(chunks[0].text)}\")\n",
    "print(f\"  text snippet='{chunks[0].text[:200]}...'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "09857697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks\n",
      "  Number of Chunks: 43\n",
      "  Number of Characters: 41196\n",
      "  Number of Words: 6381\n",
      "  Chars per Chunk: 958.05\n",
      "  Words per Chunk: 148.40\n",
      "  Min. Words per Chunk: 25\n",
      "  Max. Words per Chunk: 255\n"
     ]
    }
   ],
   "source": [
    "chunk_word_lengths = [len(c.text.split()) for c in chunks]\n",
    "chunk_char_lengths = [len(c.text) for c in chunks]\n",
    "\n",
    "print(\"Chunks\")\n",
    "print(f\"  Number of Chunks: {len(chunks)}\")\n",
    "print(f\"  Number of Characters: {sum(chunk_char_lengths)}\")\n",
    "print(f\"  Number of Words: {sum(chunk_word_lengths)}\")\n",
    "print(f\"  Chars per Chunk: {np.mean(chunk_char_lengths):.2f}\")\n",
    "print(f\"  Words per Chunk: {np.mean(chunk_word_lengths):.2f}\")\n",
    "print(f\"  Min. Words per Chunk: {np.min(chunk_word_lengths)}\")\n",
    "print(f\"  Max. Words per Chunk: {np.max(chunk_word_lengths)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f67abca",
   "metadata": {},
   "source": [
    "#### Exporting: Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e1689c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_records = [\n",
    "    {\n",
    "        \"chunk_id\": c.chunk_id,\n",
    "        \"section\": c.section,\n",
    "        \"subsection\": c.subsection,\n",
    "        \"block_index\": c.block_index,\n",
    "        \"chunk_index\": c.chunk_index,\n",
    "        \"text\": c.text,\n",
    "    }\n",
    "    for c in chunks\n",
    "]\n",
    "\n",
    "with open(\"Bhatla_chunks.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(chunk_records, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59cace1",
   "metadata": {},
   "source": [
    "### Embedding: BAAI/bge-base-en-v1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b1197b",
   "metadata": {},
   "source": [
    "#### Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "1d08da4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Model: 'BAAI/bge-base-en-v1.5' on Device: cuda\n"
     ]
    }
   ],
   "source": [
    "embed_model = SentenceTransformer(embed_model_name, device=device)\n",
    "print(f\"Embedding Model: '{embed_model_name}' on Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8183cf",
   "metadata": {},
   "source": [
    "#### Embedding Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5486cac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_texts(texts: List[str], batch_size: int = 32, is_query: bool = False) -> np.ndarray:\n",
    "    if is_query:\n",
    "        prefixed = [f\"query: {t}\" for t in texts]\n",
    "    else:\n",
    "        prefixed = [f\"passage: {t}\" for t in texts]\n",
    "    embeddings = embed_model.encode(\n",
    "        prefixed,\n",
    "        batch_size=batch_size,\n",
    "        convert_to_numpy=True,\n",
    "        normalize_embeddings=True,\n",
    "        show_progress_bar=True,\n",
    "    )\n",
    "    return embeddings\n",
    "\n",
    "def embed_query(query: str) -> np.ndarray:\n",
    "    return embed_texts([query], batch_size=1, is_query=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b91dce51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 43 Chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 2/2 [00:01<00:00,  1.35it/s]\n"
     ]
    }
   ],
   "source": [
    "chunk_texts = [c.text for c in chunks]\n",
    "print(f\"Embedding {len(chunk_texts)} Chunks...\")\n",
    "chunk_embeddings = embed_texts(chunk_texts, batch_size=32, is_query=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a5a5fb2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Shape: (43, 768)\n"
     ]
    }
   ],
   "source": [
    "print(\"Embedding Shape:\", chunk_embeddings.shape)\n",
    "assert chunk_embeddings.shape[0] == len(chunks)\n",
    "assert chunk_embeddings.shape[1] == embed_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a272096",
   "metadata": {},
   "source": [
    "#### Exporting: Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e80e6602",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"Bhatla_embeddings.npy\", chunk_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a599c87",
   "metadata": {},
   "source": [
    "### Reranker: BAAI/bge-reranker-base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1b0986",
   "metadata": {},
   "source": [
    "#### Reranker Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8d9453df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranker Model: 'BAAI/bge-reranker-base' on Device: cuda\n"
     ]
    }
   ],
   "source": [
    "reranker = CrossEncoder(\n",
    "    reranker_model_name,\n",
    "    device=device,\n",
    "    max_length=512,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "print(f\"Reranker Model: '{reranker_model_name}' on Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447f4e94",
   "metadata": {},
   "source": [
    "#### Reranker Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1f41dd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank_with_bge_reranker(\n",
    "    query: str,\n",
    "    retrieved_results: List[Dict],\n",
    "    top_k: Optional[int] = None,\n",
    ") -> List[Dict]:\n",
    "    if not retrieved_results:\n",
    "        return []\n",
    "\n",
    "    texts = [r[\"payload\"][\"text\"] for r in retrieved_results]\n",
    "    pairs = [(query, t) for t in texts]\n",
    "\n",
    "    scores = reranker.predict(pairs)\n",
    "\n",
    "    for r, s in zip(retrieved_results, scores):\n",
    "        r[\"rerank_score\"] = float(s)\n",
    "\n",
    "    reranked = sorted(retrieved_results, key=lambda x: x[\"rerank_score\"], reverse=True)\n",
    "\n",
    "    if top_k is not None:\n",
    "        reranked = reranked[:top_k]\n",
    "\n",
    "    return reranked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8175fbc",
   "metadata": {},
   "source": [
    "### Vector Store: Qdrant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24529a96",
   "metadata": {},
   "source": [
    "#### Vector Store Setup and Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0fccf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "os.makedirs(\"qdrant\", exist_ok=True)\n",
    "\n",
    "if subprocess.run([\"docker\", \"start\", \"qdrant\"]).returncode != 0:\n",
    "    subprocess.run([\n",
    "        \"docker\", \"run\", \"-d\",\n",
    "        \"--name\", \"qdrant\",\n",
    "        \"-p\", \"6333:6333\",\n",
    "        \"-v\", f\"{os.getcwd()}\\\\qdrant:/qdrant/storage\",\n",
    "        \"qdrant/qdrant:latest\"\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "23282bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qdrant at http://localhost:6333\n"
     ]
    }
   ],
   "source": [
    "qdrant = QdrantClient(url=qdrant_url)\n",
    "print(f\"Qdrant at {qdrant_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1eda539e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted Old Collection 'bhatla_credit_fraud'\n",
      "Created New Collection 'bhatla_credit_fraud' with Dimension:768\n"
     ]
    }
   ],
   "source": [
    "def recreate_collection_if_needed(\n",
    "    client: QdrantClient,\n",
    "    collection_name: str,\n",
    "    vector_dim: int,\n",
    "):\n",
    "    if client.collection_exists(collection_name):\n",
    "        client.delete_collection(collection_name)\n",
    "        print(f\"Deleted Old Collection '{collection_name}'\")\n",
    "\n",
    "    client.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config=qmodels.VectorParams(\n",
    "            size=vector_dim,\n",
    "            distance=qmodels.Distance.COSINE,\n",
    "        ),\n",
    "    )\n",
    "    print(f\"Created New Collection '{collection_name}' with Dimension:{vector_dim}\")\n",
    "\n",
    "recreate_collection_if_needed(qdrant, qdrant_collection, embed_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f958d96",
   "metadata": {},
   "source": [
    "#### Vector Store Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4ff55093",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading to Qdrant:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading to Qdrant: 100%|██████████| 1/1 [00:00<00:00,  7.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 43 / 43 Chunks to Qdrant Collection: 'bhatla_credit_fraud'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def upload_chunks_to_qdrant(\n",
    "    client: QdrantClient,\n",
    "    collection_name: str,\n",
    "    chunks: List[Chunk],\n",
    "    embeddings: np.ndarray,\n",
    "    batch_size: int = 128,\n",
    "):\n",
    "    assert len(chunks) == embeddings.shape[0]\n",
    "    total = len(chunks)\n",
    "    uploaded = 0\n",
    "\n",
    "    for i in tqdm(range(0, len(chunks), batch_size), desc=\"Uploading to Qdrant\"):\n",
    "        batch_chunks = chunks[i : i + batch_size]\n",
    "        batch_vectors = embeddings[i : i + batch_size]\n",
    "\n",
    "        points = []\n",
    "        for c, v in zip(batch_chunks, batch_vectors):\n",
    "            payload = {\n",
    "                \"chunk_id\": c.chunk_id,\n",
    "                \"section\": c.section,\n",
    "                \"subsection\": c.subsection,\n",
    "                \"block_index\": c.block_index,\n",
    "                \"chunk_index\": c.chunk_index,\n",
    "                \"text\": c.text,\n",
    "            }\n",
    "            points.append(\n",
    "                qmodels.PointStruct(\n",
    "                    id=c.chunk_id,\n",
    "                    vector=v.tolist(),\n",
    "                    payload=payload,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        client.upsert(\n",
    "            collection_name=collection_name,\n",
    "            points=points,\n",
    "        )\n",
    "        uploaded += len(batch_chunks)\n",
    "\n",
    "    print(f\"Uploaded {uploaded} / {total} Chunks to Qdrant Collection: '{collection_name}'\")\n",
    "\n",
    "upload_chunks_to_qdrant(qdrant, qdrant_collection, chunks, chunk_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2144961a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qdrant Collection Info:\n",
      "status=<CollectionStatus.GREEN: 'green'> optimizer_status=<OptimizersStatusOneOf.OK: 'ok'> warnings=None indexed_vectors_count=0 points_count=43 segments_count=8 config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=768, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None, datatype=None, multivector_config=None), shard_number=1, sharding_method=None, replication_factor=1, write_consistency_factor=1, read_fan_out_factor=None, on_disk_payload=True, sparse_vectors=None), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None, inline_storage=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=None, indexing_threshold=10000, flush_interval_sec=5, max_optimization_threads=None), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0, wal_retain_closed=1), quantization_config=None, strict_mode_config=None, metadata=None) payload_schema={}\n"
     ]
    }
   ],
   "source": [
    "info = qdrant.get_collection(qdrant_collection)\n",
    "print(\"Qdrant Collection Info:\")\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0072875",
   "metadata": {},
   "source": [
    "#### Vector Store Search Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "644d1438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_qdrant(\n",
    "    client: QdrantClient,\n",
    "    collection_name: str,\n",
    "    query: str,\n",
    "    top_k: int = 20,\n",
    ") -> List[Dict]:\n",
    "    # 1. Turn the text query into an embedding\n",
    "    query_vector = embed_query(query)  # should return a 1D numpy array of length 768\n",
    "\n",
    "    # 2. Use the new universal query_points API\n",
    "    #    - `query` is the vector (list[float])\n",
    "    #    - It returns a QueryResponse, whose .points is a list[ScoredPoint]\n",
    "    response: QueryResponse = client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=query_vector.tolist(),   # dense vector\n",
    "        limit=top_k,\n",
    "        with_payload=True,             # attach payloads to results\n",
    "        # with_vectors=False by default; set True if you also want stored vectors\n",
    "    )\n",
    "\n",
    "    # 3. Normalize output into your desired format\n",
    "    output: List[Dict] = []\n",
    "    for p in response.points:\n",
    "        output.append(\n",
    "            {\n",
    "                \"id\": p.id,\n",
    "                \"score\": p.score,\n",
    "                \"payload\": p.payload,\n",
    "                # you could optionally add \"vector\": p.vector if you call with_vectors=True\n",
    "            }\n",
    "        )\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705362d2",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b35a87",
   "metadata": {},
   "source": [
    "#### Vector Store Search Function w/ Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "60d7f741",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval Results for Query: 'What is Application Fraud?'\n",
      "  rank 1, score=0.6864, section=Card Related Frauds, subsection=APPLICATION FRAUD\n",
      "    text snippet='This type of fraud occurs when a person falsifies an application to acquire a credit card. Application fraud can be committed in three ways: Assumed i...'\n",
      "  rank 2, score=0.6568, section=Merchant Related Frauds, subsection=TRIANGULATION\n",
      "    text snippet='The fraudster in this type of fraud operates from a web site. Goods are offered at heavily discounted rates and are also shipped before payment. The f...'\n",
      "  rank 3, score=0.6496, section=Card Related Frauds, subsection=ACCOUNT TAKEOVER\n",
      "    text snippet='This type of fraud occurs when a fraudster illegally obtains a valid customers’ personal information. The fraudster takes control of (takeover) a legi...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_query = \"What is Application Fraud?\"\n",
    "dense_test_results = search_qdrant(qdrant, qdrant_collection, test_query, top_k=3)\n",
    "print(f\"Retrieval Results for Query: '{test_query}'\")\n",
    "for i, r in enumerate(dense_test_results, start=1):\n",
    "    print(f\"  rank {i}, score={r['score']:.4f}, section={r['payload'].get('section')}, subsection={r['payload'].get('subsection')}\")\n",
    "    print(f\"    text snippet='{r['payload']['text'][:150]}...'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "cabaf50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 109.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval Results for Query: 'What is the Technology for Detecting Credit Card Frauds?'\n",
      "  rank 1, score=0.7153, section=Fraud Prevention Technologies, subsection=None\n",
      "    text snippet='While fraudsters are using sophisticated methods to gain access to credit card information and perpetrate fraud, new technologies are available to hel...'\n",
      "  rank 2, score=0.6974, section=Recent Developments in Fraud Management, subsection=None\n",
      "    text snippet='The technology for detecting credit card frauds is advancing at a rapid pace – rules based systems, neural networks, chip cards and biometrics are som...'\n",
      "  rank 3, score=0.6891, section=Merchant Related Frauds, subsection=TRIANGULATION\n",
      "    text snippet='The fraudster in this type of fraud operates from a web site. Goods are offered at heavily discounted rates and are also shipped before payment. The f...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_query = \"What is the Technology for Detecting Credit Card Frauds?\"\n",
    "dense_test_results = search_qdrant(qdrant, qdrant_collection, test_query, top_k=3)\n",
    "print(f\"Retrieval Results for Query: '{test_query}'\")\n",
    "for i, r in enumerate(dense_test_results, start=1):\n",
    "    print(f\"  rank {i}, score={r['score']:.4f}, section={r['payload'].get('section')}, subsection={r['payload'].get('subsection')}\")\n",
    "    print(f\"    text snippet='{r['payload']['text'][:150]}...'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e893c61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 97.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval Results for Query: 'What is the Key to Minimize Cost of Review?'\n",
      "  rank 1, score=0.6770, section=Managing the Total Cost of Fraud, subsection=None\n",
      "    text snippet='Explanation: The figure compares three levels of transaction screening and illustrates how each affects the total cost of fraud. With insufficient scr...'\n",
      "  rank 2, score=0.6691, section=Managing the Total Cost of Fraud, subsection=None\n",
      "    text snippet='An efficient fraud management solution is one that minimizes the total cost of fraud, which includes the financial loss due to fraud as well as the co...'\n",
      "  rank 3, score=0.6589, section=Managing the Total Cost of Fraud, subsection=None\n",
      "    text snippet='The direct aspect is the cost of human resources dedicated to the review. This cost is directly proportional to the volume of transactions being subje...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_query = \"What is the Key to Minimize Cost of Review?\"\n",
    "dense_test_results = search_qdrant(qdrant, qdrant_collection, test_query, top_k=3)\n",
    "print(f\"Retrieval Results for Query: '{test_query}'\")\n",
    "for i, r in enumerate(dense_test_results, start=1):\n",
    "    print(f\"  rank {i}, score={r['score']:.4f}, section={r['payload'].get('section')}, subsection={r['payload'].get('subsection')}\")\n",
    "    print(f\"    text snippet='{r['payload']['text'][:150]}...'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dd9607",
   "metadata": {},
   "source": [
    "#### Vector Store Search Function w/ Embedding & Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "5403eb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 53.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval Results for Query: 'What is Application Fraud?'\n",
      "  rank 1, score=0.6864, section=Card Related Frauds, subsection=APPLICATION FRAUD\n",
      "    text snippet='This type of fraud occurs when a person falsifies an application to acquire a credit card. Application fraud can be committed in three ways: Assumed i...'\n",
      "  rank 2, score=0.6568, section=Merchant Related Frauds, subsection=TRIANGULATION\n",
      "    text snippet='The fraudster in this type of fraud operates from a web site. Goods are offered at heavily discounted rates and are also shipped before payment. The f...'\n",
      "  rank 3, score=0.6496, section=Card Related Frauds, subsection=ACCOUNT TAKEOVER\n",
      "    text snippet='This type of fraud occurs when a fraudster illegally obtains a valid customers’ personal information. The fraudster takes control of (takeover) a legi...'\n",
      "  rank 4, score=0.6479, section=Introduction, subsection=None\n",
      "    text snippet='According to a recent survey, the rate at which internet fraud occurs is 12 to 15 times higher than ‘physical world’ fraud. However, recent technical ...'\n",
      "  rank 5, score=0.6351, section=Merchant Related Frauds, subsection=MERCHANT COLLUSION\n",
      "    text snippet='This type of fraud occurs when merchant owners and/or their employees conspire to commit fraud using their customers’ (cardholder) accounts and/or per...'\n",
      "\n",
      "Reranked Retrieval Results for query: 'What is Application Fraud?'\n",
      "  rerank 1, rerank_score=0.6353, section=Card Related Frauds, subsection=APPLICATION FRAUD\n",
      "    text snippet='This type of fraud occurs when a person falsifies an application to acquire a credit card. Application fraud can be committed in three ways: Assumed i...'\n",
      "  rerank 2, rerank_score=0.1457, section=Card Related Frauds, subsection=ACCOUNT TAKEOVER\n",
      "    text snippet='This type of fraud occurs when a fraudster illegally obtains a valid customers’ personal information. The fraudster takes control of (takeover) a legi...'\n",
      "  rerank 3, rerank_score=0.0527, section=Merchant Related Frauds, subsection=MERCHANT COLLUSION\n",
      "    text snippet='This type of fraud occurs when merchant owners and/or their employees conspire to commit fraud using their customers’ (cardholder) accounts and/or per...'\n",
      "  rerank 4, rerank_score=0.0499, section=Merchant Related Frauds, subsection=TRIANGULATION\n",
      "    text snippet='The fraudster in this type of fraud operates from a web site. Goods are offered at heavily discounted rates and are also shipped before payment. The f...'\n",
      "  rerank 5, rerank_score=0.0001, section=Introduction, subsection=None\n",
      "    text snippet='According to a recent survey, the rate at which internet fraud occurs is 12 to 15 times higher than ‘physical world’ fraud. However, recent technical ...'\n"
     ]
    }
   ],
   "source": [
    "test_query = \"What is Application Fraud?\"\n",
    "dense_test_results = search_qdrant(qdrant, qdrant_collection, test_query, top_k=5)\n",
    "print(f\"Retrieval Results for Query: '{test_query}'\")\n",
    "for i, r in enumerate(dense_test_results, start=1):\n",
    "    print(f\"  rank {i}, score={r['score']:.4f}, section={r['payload'].get('section')}, subsection={r['payload'].get('subsection')}\")\n",
    "    print(f\"    text snippet='{r['payload']['text'][:150]}...'\")\n",
    "    \n",
    "    \n",
    "reranked_test_results = rerank_with_bge_reranker(test_query, dense_test_results, top_k=5)\n",
    "print(f\"\\nReranked Retrieval Results for query: '{test_query}'\")\n",
    "for i, r in enumerate(reranked_test_results, start=1):\n",
    "    print(f\"  rerank {i}, rerank_score={r['rerank_score']:.4f}, section={r['payload'].get('section')}, subsection={r['payload'].get('subsection')}\")\n",
    "    print(f\"    text snippet='{r['payload']['text'][:150]}...'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c0e121bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 81.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval Results for Query: 'What is the Technology for Detecting Credit Card Frauds?'\n",
      "  rank 1, score=0.7153, section=Fraud Prevention Technologies, subsection=None\n",
      "    text snippet='While fraudsters are using sophisticated methods to gain access to credit card information and perpetrate fraud, new technologies are available to hel...'\n",
      "  rank 2, score=0.6974, section=Recent Developments in Fraud Management, subsection=None\n",
      "    text snippet='The technology for detecting credit card frauds is advancing at a rapid pace – rules based systems, neural networks, chip cards and biometrics are som...'\n",
      "  rank 3, score=0.6891, section=Merchant Related Frauds, subsection=TRIANGULATION\n",
      "    text snippet='The fraudster in this type of fraud operates from a web site. Goods are offered at heavily discounted rates and are also shipped before payment. The f...'\n",
      "  rank 4, score=0.6870, section=Card Related Frauds, subsection=FAKE AND COUNTERFEIT CARDS\n",
      "    text snippet='The creation of counterfeit cards, together with lost / stolen cards pose highest threat in credit card frauds. Fraudsters are constantly finding new ...'\n",
      "  rank 5, score=0.6869, section=Introduction, subsection=None\n",
      "    text snippet='Credit Card Fraud is one of the biggest threats to business establishments today. However, to combat the fraud effectively, it is important to first u...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reranked Retrieval Results for query: 'What is the Technology for Detecting Credit Card Frauds?'\n",
      "  rerank 1, rerank_score=0.9453, section=Recent Developments in Fraud Management, subsection=None\n",
      "    text snippet='The technology for detecting credit card frauds is advancing at a rapid pace – rules based systems, neural networks, chip cards and biometrics are som...'\n",
      "  rerank 2, rerank_score=0.8490, section=Fraud Prevention Technologies, subsection=None\n",
      "    text snippet='While fraudsters are using sophisticated methods to gain access to credit card information and perpetrate fraud, new technologies are available to hel...'\n",
      "  rerank 3, rerank_score=0.4593, section=Introduction, subsection=None\n",
      "    text snippet='Credit Card Fraud is one of the biggest threats to business establishments today. However, to combat the fraud effectively, it is important to first u...'\n",
      "  rerank 4, rerank_score=0.0941, section=Card Related Frauds, subsection=FAKE AND COUNTERFEIT CARDS\n",
      "    text snippet='The creation of counterfeit cards, together with lost / stolen cards pose highest threat in credit card frauds. Fraudsters are constantly finding new ...'\n",
      "  rerank 5, rerank_score=0.0436, section=Merchant Related Frauds, subsection=TRIANGULATION\n",
      "    text snippet='The fraudster in this type of fraud operates from a web site. Goods are offered at heavily discounted rates and are also shipped before payment. The f...'\n"
     ]
    }
   ],
   "source": [
    "test_query = \"What is the Technology for Detecting Credit Card Frauds?\"\n",
    "dense_test_results = search_qdrant(qdrant, qdrant_collection, test_query, top_k=5)\n",
    "print(f\"Retrieval Results for Query: '{test_query}'\")\n",
    "for i, r in enumerate(dense_test_results, start=1):\n",
    "    print(f\"  rank {i}, score={r['score']:.4f}, section={r['payload'].get('section')}, subsection={r['payload'].get('subsection')}\")\n",
    "    print(f\"    text snippet='{r['payload']['text'][:150]}...'\")\n",
    "    \n",
    "reranked_test_results = rerank_with_bge_reranker(test_query, dense_test_results, top_k=5)\n",
    "print(f\"\\nReranked Retrieval Results for query: '{test_query}'\")\n",
    "for i, r in enumerate(reranked_test_results, start=1):\n",
    "    print(f\"  rerank {i}, rerank_score={r['rerank_score']:.4f}, section={r['payload'].get('section')}, subsection={r['payload'].get('subsection')}\")\n",
    "    print(f\"    text snippet='{r['payload']['text'][:150]}...'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3c1af0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 105.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval Results for Query: 'What is the Key to Minimize Cost of Review?'\n",
      "  rank 1, score=0.6770, section=Managing the Total Cost of Fraud, subsection=None\n",
      "    text snippet='Explanation: The figure compares three levels of transaction screening and illustrates how each affects the total cost of fraud. With insufficient scr...'\n",
      "  rank 2, score=0.6691, section=Managing the Total Cost of Fraud, subsection=None\n",
      "    text snippet='An efficient fraud management solution is one that minimizes the total cost of fraud, which includes the financial loss due to fraud as well as the co...'\n",
      "  rank 3, score=0.6589, section=Managing the Total Cost of Fraud, subsection=None\n",
      "    text snippet='The direct aspect is the cost of human resources dedicated to the review. This cost is directly proportional to the volume of transactions being subje...'\n",
      "  rank 4, score=0.6377, section=Fraud Prevention Technologies, subsection=MANUAL REVIEW\n",
      "    text snippet='This method consists of reviewing every transaction manually for signs of fraudulent activity and involves a exceedingly high level of human intervent...'\n",
      "  rank 5, score=0.6322, section=Managing the Total Cost of Fraud, subsection=None\n",
      "    text snippet='Reducing cost of computing is helping in introducing complex systems, which can analyse a fraudulent transaction in a matter of fraction of a second. ...'\n",
      "\n",
      "Reranked Retrieval Results for query: 'What is the Key to Minimize Cost of Review?'\n",
      "  rerank 1, rerank_score=0.8966, section=Managing the Total Cost of Fraud, subsection=None\n",
      "    text snippet='The direct aspect is the cost of human resources dedicated to the review. This cost is directly proportional to the volume of transactions being subje...'\n",
      "  rerank 2, rerank_score=0.0380, section=Fraud Prevention Technologies, subsection=MANUAL REVIEW\n",
      "    text snippet='This method consists of reviewing every transaction manually for signs of fraudulent activity and involves a exceedingly high level of human intervent...'\n",
      "  rerank 3, rerank_score=0.0008, section=Managing the Total Cost of Fraud, subsection=None\n",
      "    text snippet='An efficient fraud management solution is one that minimizes the total cost of fraud, which includes the financial loss due to fraud as well as the co...'\n",
      "  rerank 4, rerank_score=0.0003, section=Managing the Total Cost of Fraud, subsection=None\n",
      "    text snippet='Explanation: The figure compares three levels of transaction screening and illustrates how each affects the total cost of fraud. With insufficient scr...'\n",
      "  rerank 5, rerank_score=0.0001, section=Managing the Total Cost of Fraud, subsection=None\n",
      "    text snippet='Reducing cost of computing is helping in introducing complex systems, which can analyse a fraudulent transaction in a matter of fraction of a second. ...'\n"
     ]
    }
   ],
   "source": [
    "test_query = \"What is the Key to Minimize Cost of Review?\"\n",
    "dense_test_results = search_qdrant(qdrant, qdrant_collection, test_query, top_k=5)\n",
    "print(f\"Retrieval Results for Query: '{test_query}'\")\n",
    "for i, r in enumerate(dense_test_results, start=1):\n",
    "    print(f\"  rank {i}, score={r['score']:.4f}, section={r['payload'].get('section')}, subsection={r['payload'].get('subsection')}\")\n",
    "    print(f\"    text snippet='{r['payload']['text'][:150]}...'\")\n",
    "    \n",
    "reranked_test_results = rerank_with_bge_reranker(test_query, dense_test_results, top_k=5)\n",
    "print(f\"\\nReranked Retrieval Results for query: '{test_query}'\")\n",
    "for i, r in enumerate(reranked_test_results, start=1):\n",
    "    print(f\"  rerank {i}, rerank_score={r['rerank_score']:.4f}, section={r['payload'].get('section')}, subsection={r['payload'].get('subsection')}\")\n",
    "    print(f\"    text snippet='{r['payload']['text'][:150]}...'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36fab37",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8650ff",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46e60220",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\envs\\ai\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import List, Dict, Optional, Any\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import QueryResponse\n",
    "from qdrant_client.http import models as qmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba69573",
   "metadata": {},
   "source": [
    "### Config & Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c847f43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_url = \"http://localhost:6333\"\n",
    "qdrant_collection = \"bhatla_credit_fraud\"\n",
    "\n",
    "embed_model_name = \"BAAI/bge-base-en-v1.5\"\n",
    "embed_dim = 768\n",
    "\n",
    "reranker_model_name = \"BAAI/bge-reranker-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac5e487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Bhatla_chunks.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    chunk_records: List[Dict] = json.load(f)\n",
    "\n",
    "chunk_embeddings: np.ndarray = np.load(\"Bhatla_embeddings.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36046722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5855b229",
   "metadata": {},
   "source": [
    "### Embedding: BAAI/bge-base-en-v1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd22c31d",
   "metadata": {},
   "source": [
    "#### Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d0fbfb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Model: 'BAAI/bge-base-en-v1.5' on Device: cuda\n"
     ]
    }
   ],
   "source": [
    "embed_model = SentenceTransformer(embed_model_name, device=device)\n",
    "print(f\"Embedding Model: '{embed_model_name}' on Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bac95c0",
   "metadata": {},
   "source": [
    "#### Embedding Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6f10882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_texts(texts: List[str], batch_size: int = 32, is_query: bool = False) -> np.ndarray:\n",
    "    if is_query:\n",
    "        prefixed = [f\"query: {t}\" for t in texts]\n",
    "    else:\n",
    "        prefixed = [f\"passage: {t}\" for t in texts]\n",
    "    embeddings = embed_model.encode(\n",
    "        prefixed,\n",
    "        batch_size=batch_size,\n",
    "        convert_to_numpy=True,\n",
    "        normalize_embeddings=True,\n",
    "        show_progress_bar=True,\n",
    "    )\n",
    "    return embeddings\n",
    "\n",
    "def embed_query(query: str) -> np.ndarray:\n",
    "    return embed_texts([query], batch_size=1, is_query=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab615a7",
   "metadata": {},
   "source": [
    "### Reranker: BAAI/bge-reranker-base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1d1b42",
   "metadata": {},
   "source": [
    "#### Reranker Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e6a2ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranker Model: 'BAAI/bge-reranker-base' on Device: cuda\n"
     ]
    }
   ],
   "source": [
    "reranker = CrossEncoder(\n",
    "    reranker_model_name,\n",
    "    device=device,\n",
    "    max_length=512,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "print(f\"Reranker Model: '{reranker_model_name}' on Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf937a2",
   "metadata": {},
   "source": [
    "#### Reranker Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9a1da1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank_with_bge_reranker(\n",
    "    query: str,\n",
    "    retrieved_results: List[Dict],\n",
    "    top_k: Optional[int] = None,\n",
    ") -> List[Dict]:\n",
    "    if not retrieved_results:\n",
    "        return []\n",
    "\n",
    "    texts = [r[\"payload\"][\"text\"] for r in retrieved_results]\n",
    "    pairs = [(query, t) for t in texts]\n",
    "\n",
    "    scores = reranker.predict(pairs)\n",
    "\n",
    "    for r, s in zip(retrieved_results, scores):\n",
    "        r[\"rerank_score\"] = float(s)\n",
    "\n",
    "    reranked = sorted(retrieved_results, key=lambda x: x[\"rerank_score\"], reverse=True)\n",
    "\n",
    "    if top_k is not None:\n",
    "        reranked = reranked[:top_k]\n",
    "\n",
    "    return reranked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbb4147",
   "metadata": {},
   "source": [
    "### Vector Store: Qdrant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14447336",
   "metadata": {},
   "source": [
    "#### Vector Store Setup and Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06237d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "os.makedirs(\"qdrant\", exist_ok=True)\n",
    "\n",
    "if subprocess.run([\"docker\", \"start\", \"qdrant\"]).returncode != 0:\n",
    "    subprocess.run([\n",
    "        \"docker\", \"run\", \"-d\",\n",
    "        \"--name\", \"qdrant\",\n",
    "        \"-p\", \"6333:6333\",\n",
    "        \"-v\", f\"{os.getcwd()}\\\\qdrant:/qdrant/storage\",\n",
    "        \"qdrant/qdrant:latest\"\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22dfbf20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qdrant at http://localhost:6333\n"
     ]
    }
   ],
   "source": [
    "qdrant = QdrantClient(url=qdrant_url)\n",
    "print(f\"Qdrant at {qdrant_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c5a4ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted Old Collection 'bhatla_credit_fraud'\n",
      "Created New Collection 'bhatla_credit_fraud' with Dimension:768\n"
     ]
    }
   ],
   "source": [
    "def recreate_collection_if_needed(\n",
    "    client: QdrantClient,\n",
    "    collection_name: str,\n",
    "    vector_dim: int,\n",
    "):\n",
    "    if client.collection_exists(collection_name):\n",
    "        client.delete_collection(collection_name)\n",
    "        print(f\"Deleted Old Collection '{collection_name}'\")\n",
    "\n",
    "    client.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config=qmodels.VectorParams(\n",
    "            size=vector_dim,\n",
    "            distance=qmodels.Distance.COSINE,\n",
    "        ),\n",
    "    )\n",
    "    print(f\"Created New Collection '{collection_name}' with Dimension:{vector_dim}\")\n",
    "\n",
    "recreate_collection_if_needed(qdrant, qdrant_collection, embed_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6ab866",
   "metadata": {},
   "source": [
    "#### Vector Store Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed34e8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 43 / 43 Chunks to Qdrant Collection: 'bhatla_credit_fraud'\n"
     ]
    }
   ],
   "source": [
    "def upload_saved_chunks_to_qdrant(\n",
    "    client: QdrantClient,\n",
    "    collection_name: str,\n",
    "    chunk_records: List[Dict],\n",
    "    embeddings: np.ndarray,\n",
    "    batch_size: int = 128,\n",
    "):\n",
    "    assert len(chunk_records) == embeddings.shape[0]\n",
    "    total = len(chunk_records)\n",
    "    uploaded = 0\n",
    "\n",
    "    for i in range(0, total, batch_size):\n",
    "        batch_records = chunk_records[i : i + batch_size]\n",
    "        batch_vectors = embeddings[i : i + batch_size]\n",
    "\n",
    "        points = []\n",
    "        for rec, vec in zip(batch_records, batch_vectors):\n",
    "            payload = {\n",
    "                \"chunk_id\": rec[\"chunk_id\"],\n",
    "                \"section\": rec.get(\"section\"),\n",
    "                \"subsection\": rec.get(\"subsection\"),\n",
    "                \"block_index\": rec.get(\"block_index\"),\n",
    "                \"chunk_index\": rec.get(\"chunk_index\"),\n",
    "                \"text\": rec[\"text\"],\n",
    "            }\n",
    "\n",
    "            points.append(\n",
    "                qmodels.PointStruct(\n",
    "                    id=rec[\"chunk_id\"],\n",
    "                    vector=vec.tolist(),\n",
    "                    payload=payload,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        client.upsert(collection_name=collection_name, points=points)\n",
    "        uploaded += len(batch_records)\n",
    "\n",
    "    print(f\"Uploaded {uploaded} / {total} Chunks to Qdrant Collection: '{collection_name}'\")\n",
    "\n",
    "\n",
    "upload_saved_chunks_to_qdrant(qdrant, qdrant_collection, chunk_records, chunk_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed766862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qdrant Collection Info:\n",
      "status=<CollectionStatus.GREEN: 'green'> optimizer_status=<OptimizersStatusOneOf.OK: 'ok'> warnings=None indexed_vectors_count=0 points_count=43 segments_count=8 config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=768, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None, datatype=None, multivector_config=None), shard_number=1, sharding_method=None, replication_factor=1, write_consistency_factor=1, read_fan_out_factor=None, on_disk_payload=True, sparse_vectors=None), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None, inline_storage=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=None, indexing_threshold=10000, flush_interval_sec=5, max_optimization_threads=None), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0, wal_retain_closed=1), quantization_config=None, strict_mode_config=None, metadata=None) payload_schema={}\n"
     ]
    }
   ],
   "source": [
    "info = qdrant.get_collection(qdrant_collection)\n",
    "print(\"Qdrant Collection Info:\")\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a24d164",
   "metadata": {},
   "source": [
    "#### Vector Store Search Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41912062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_qdrant(\n",
    "    client: QdrantClient,\n",
    "    collection_name: str,\n",
    "    query: str,\n",
    "    top_k: int = 20,\n",
    ") -> List[Dict]:\n",
    "    # 1. Turn the text query into an embedding\n",
    "    query_vector = embed_query(query)  # should return a 1D numpy array of length 768\n",
    "\n",
    "    # 2. Use the new universal query_points API\n",
    "    #    - `query` is the vector (list[float])\n",
    "    #    - It returns a QueryResponse, whose .points is a list[ScoredPoint]\n",
    "    response: QueryResponse = client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=query_vector.tolist(),   # dense vector\n",
    "        limit=top_k,\n",
    "        with_payload=True,             # attach payloads to results\n",
    "        # with_vectors=False by default; set True if you also want stored vectors\n",
    "    )\n",
    "\n",
    "    # 3. Normalize output into your desired format\n",
    "    output: List[Dict] = []\n",
    "    for p in response.points:\n",
    "        output.append(\n",
    "            {\n",
    "                \"id\": p.id,\n",
    "                \"score\": p.score,\n",
    "                \"payload\": p.payload,\n",
    "                # you could optionally add \"vector\": p.vector if you call with_vectors=True\n",
    "            }\n",
    "        )\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea5c32f",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ed9510b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_chunks(\n",
    "    query: str,\n",
    "    top_k: int = 5,\n",
    "    use_reranker: bool = True,\n",
    ") -> List[Dict]:\n",
    "    dense_results = search_qdrant(qdrant, qdrant_collection, query, top_k=top_k)\n",
    "\n",
    "    if not use_reranker:\n",
    "        return dense_results\n",
    "\n",
    "    reranked_results = rerank_with_bge_reranker(query, dense_results, top_k=top_k)\n",
    "    return reranked_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc7a27ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_results(\n",
    "    query: str,\n",
    "    results: List[Dict],\n",
    "    max_chars: int = 200,\n",
    "):\n",
    "    print(f\"Retrieval Results for Query: '{query}'\")\n",
    "    if not results:\n",
    "        print(\"No Result\")\n",
    "        return\n",
    "\n",
    "    for i, r in enumerate(results, start=1):\n",
    "        base_score = r.get(\"score\", None)\n",
    "        rerank_score = r.get(\"rerank_score\", None)\n",
    "        section = r[\"payload\"].get(\"section\")\n",
    "        subsection = r[\"payload\"].get(\"subsection\")\n",
    "        text_snippet = r[\"payload\"][\"text\"][:max_chars].replace(\"\\n\", \" \")\n",
    "\n",
    "        print(f\"rank {i}\")\n",
    "        if base_score is not None:\n",
    "            print(f\"    dense_score:   {base_score:.4f}\")\n",
    "        if rerank_score is not None:\n",
    "            print(f\"    rerank_score:  {rerank_score:.4f}\")\n",
    "        print(f\"    section:       {section}\")\n",
    "        print(f\"    subsection:    {subsection}\")\n",
    "        print(f\"    snippet:       '{text_snippet}...'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "099a5dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval Results for Query: 'What is Application Fraud?'\n",
      "rank 1\n",
      "    dense_score:   0.6864\n",
      "    rerank_score:  0.6353\n",
      "    section:       Card Related Frauds\n",
      "    subsection:    APPLICATION FRAUD\n",
      "    snippet:       'This type of fraud occurs when a person falsifies an application to acquire a credit card. Application fraud can be committed in three ways: Assumed identity, where an individual illegally obtains per...'\n",
      "rank 2\n",
      "    dense_score:   0.6496\n",
      "    rerank_score:  0.1457\n",
      "    section:       Card Related Frauds\n",
      "    subsection:    ACCOUNT TAKEOVER\n",
      "    snippet:       'This type of fraud occurs when a fraudster illegally obtains a valid customers’ personal information. The fraudster takes control of (takeover) a legitimate account by either providing the customers a...'\n",
      "rank 3\n",
      "    dense_score:   0.6351\n",
      "    rerank_score:  0.0527\n",
      "    section:       Merchant Related Frauds\n",
      "    subsection:    MERCHANT COLLUSION\n",
      "    snippet:       'This type of fraud occurs when merchant owners and/or their employees conspire to commit fraud using their customers’ (cardholder) accounts and/or personal information. Merchant owners and/or their em...'\n",
      "rank 4\n",
      "    dense_score:   0.6568\n",
      "    rerank_score:  0.0499\n",
      "    section:       Merchant Related Frauds\n",
      "    subsection:    TRIANGULATION\n",
      "    snippet:       'The fraudster in this type of fraud operates from a web site. Goods are offered at heavily discounted rates and are also shipped before payment. The fraudulent site appears to be a legitimate auction ...'\n",
      "rank 5\n",
      "    dense_score:   0.6479\n",
      "    rerank_score:  0.0001\n",
      "    section:       Introduction\n",
      "    subsection:    None\n",
      "    snippet:       'According to a recent survey, the rate at which internet fraud occurs is 12 to 15 times higher than ‘physical world’ fraud. However, recent technical developments are showing some promise to check fra...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 117.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval Results for Query: 'What is the Technology for Detecting Credit Card Frauds?'\n",
      "rank 1\n",
      "    dense_score:   0.6974\n",
      "    rerank_score:  0.9453\n",
      "    section:       Recent Developments in Fraud Management\n",
      "    subsection:    None\n",
      "    snippet:       'The technology for detecting credit card frauds is advancing at a rapid pace – rules based systems, neural networks, chip cards and biometrics are some of the popular techniques employed by Issuing an...'\n",
      "rank 2\n",
      "    dense_score:   0.7153\n",
      "    rerank_score:  0.8490\n",
      "    section:       Fraud Prevention Technologies\n",
      "    subsection:    None\n",
      "    snippet:       'While fraudsters are using sophisticated methods to gain access to credit card information and perpetrate fraud, new technologies are available to help merchants to detect and prevent fraudulent trans...'\n",
      "rank 3\n",
      "    dense_score:   0.6869\n",
      "    rerank_score:  0.4593\n",
      "    section:       Introduction\n",
      "    subsection:    None\n",
      "    snippet:       'Credit Card Fraud is one of the biggest threats to business establishments today. However, to combat the fraud effectively, it is important to first understand the mechanisms of executing a fraud. Cre...'\n",
      "rank 4\n",
      "    dense_score:   0.6870\n",
      "    rerank_score:  0.0941\n",
      "    section:       Card Related Frauds\n",
      "    subsection:    FAKE AND COUNTERFEIT CARDS\n",
      "    snippet:       'The creation of counterfeit cards, together with lost / stolen cards pose highest threat in credit card frauds. Fraudsters are constantly finding new and more innovative ways to create counterfeit car...'\n",
      "rank 5\n",
      "    dense_score:   0.6891\n",
      "    rerank_score:  0.0436\n",
      "    section:       Merchant Related Frauds\n",
      "    subsection:    TRIANGULATION\n",
      "    snippet:       'The fraudster in this type of fraud operates from a web site. Goods are offered at heavily discounted rates and are also shipped before payment. The fraudulent site appears to be a legitimate auction ...'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 124.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval Results for Query: 'What is the Key to Minimize Cost of Review?'\n",
      "rank 1\n",
      "    dense_score:   0.6589\n",
      "    rerank_score:  0.8966\n",
      "    section:       Managing the Total Cost of Fraud\n",
      "    subsection:    None\n",
      "    snippet:       'The direct aspect is the cost of human resources dedicated to the review. This cost is directly proportional to the volume of transactions being subject to the review. The indirect costs, which are ty...'\n",
      "rank 2\n",
      "    dense_score:   0.6377\n",
      "    rerank_score:  0.0380\n",
      "    section:       Fraud Prevention Technologies\n",
      "    subsection:    MANUAL REVIEW\n",
      "    snippet:       'This method consists of reviewing every transaction manually for signs of fraudulent activity and involves a exceedingly high level of human intervention. This can prove to be very expensive, as well ...'\n",
      "rank 3\n",
      "    dense_score:   0.6691\n",
      "    rerank_score:  0.0008\n",
      "    section:       Managing the Total Cost of Fraud\n",
      "    subsection:    None\n",
      "    snippet:       'An efficient fraud management solution is one that minimizes the total cost of fraud, which includes the financial loss due to fraud as well as the cost of fraud prevention systems. Too often success ...'\n",
      "rank 4\n",
      "    dense_score:   0.6770\n",
      "    rerank_score:  0.0003\n",
      "    section:       Managing the Total Cost of Fraud\n",
      "    subsection:    None\n",
      "    snippet:       'Explanation: The figure compares three levels of transaction screening and illustrates how each affects the total cost of fraud. With insufficient screening, only a small portion of transactions is re...'\n",
      "rank 5\n",
      "    dense_score:   0.6322\n",
      "    rerank_score:  0.0001\n",
      "    section:       Managing the Total Cost of Fraud\n",
      "    subsection:    None\n",
      "    snippet:       'Reducing cost of computing is helping in introducing complex systems, which can analyse a fraudulent transaction in a matter of fraction of a second. It is equally important to identify the right segm...'\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    \"What is Application Fraud?\",\n",
    "    \"What is the Technology for Detecting Credit Card Frauds?\",\n",
    "    \"What is the Key to Minimize Cost of Review?\",\n",
    "]\n",
    "\n",
    "for q in queries:\n",
    "    results = retrieve_chunks(q, top_k=5, use_reranker=True)\n",
    "    pretty_print_results(q, results, max_chars=200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
